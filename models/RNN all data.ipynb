{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc04986",
   "metadata": {},
   "source": [
    "# Notebook for LSTM - Model Testing\n",
    "\n",
    "Different layersizes, number of layers and epochs were tested and evaluated in this notebook.\n",
    "The resulting models were all saved, the best one is used for the website\n",
    "\n",
    "the notebooks RNN all lemma and RNN no party contain similar test, only difference: There an all-lemma-/no-party-matrix was used instead of the \"vector_all_data_300d-3-5\" matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0275313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load(\n",
    "    \"de_core_news_lg\", exclude=[\"tok2vec\", \"ner\", \"parser\", \"attribute_ruler\"]\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import make_sampling_table, pad_sequences\n",
    "from tensorflow.keras import Model, Sequential, Input\n",
    "from tensorflow.keras.layers import (\n",
    "    Dot,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    GlobalAveragePooling1D,\n",
    "    LSTM,\n",
    "    concatenate,\n",
    "    Dropout,\n",
    "    Bidirectional,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep learning Model 1\n",
    "\n",
    "class RnnModel():\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, max_len):\n",
    "        \n",
    "        # imput = padded sequence\n",
    "        inp1 = Input(shape=(max_len,))\n",
    "        # embedding layer: loads the word vector from the embedding matrix\n",
    "        x = Embedding(embedding_matrix.shape[0], embedding_dim, weights=[embedding_matrix])(inp1)\n",
    "        # bi-directional lstm-layer\n",
    "        x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(64))(x)\n",
    "        #densely connected layer with Rectified Linear Unit (relu) activation and 10% dropout\n",
    "        x = Dense(128, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        #densely connected layer\n",
    "        x = Dense(64, activation=\"relu\")(x)\n",
    "        # layer with the predictions\n",
    "        x = Dense(6, activation=\"softmax\")(x)    \n",
    "        model = Model(inputs=inp1, outputs=x)\n",
    "        model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
    "        self.model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71d24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "data = pd.DataFrame(columns=['tweet', 'party'])\n",
    "\n",
    "afd = pd.read_csv('../cleaned-data/AfD.csv', quoting=csv.QUOTE_NONE)['text']\n",
    "afd = pd.DataFrame([[i, 0] for i in afd], columns=['tweet', 'party'])\n",
    "\n",
    "data = data.append(afd, ignore_index=True)\n",
    "\n",
    "cdu = pd.read_csv('../cleaned-data/CDU.csv',quoting=csv.QUOTE_NONE)['text']\n",
    "csu = pd.read_csv('../cleaned-data/CSU.csv',quoting=csv.QUOTE_NONE)['text']\n",
    "\n",
    "cdu = pd.DataFrame([[i, 1] for i in cdu], columns=['tweet', 'party'])\n",
    "csu = pd.DataFrame([[i, 1] for i in csu], columns=['tweet', 'party'])\n",
    "\n",
    "data = data.append(cdu, ignore_index=True)\n",
    "data = data.append(csu, ignore_index=True)\n",
    "\n",
    "fdp = pd.read_csv('../cleaned-data/FDP.csv',quoting=csv.QUOTE_NONE)['text']\n",
    "fdp = pd.DataFrame([[i, 2] for i in fdp], columns=['tweet', 'party'])\n",
    "\n",
    "data = data.append(fdp, ignore_index=True)\n",
    "\n",
    "gru = pd.read_csv('../cleaned-data/GRÜNE.csv',quoting=csv.QUOTE_NONE)['text']\n",
    "gru = pd.DataFrame([[i, 3] for i in gru], columns=['tweet', 'party'])\n",
    "\n",
    "data = data.append(gru, ignore_index=True)\n",
    "\n",
    "lin = pd.read_csv('../cleaned-data/LINKE.csv',quoting=csv.QUOTE_NONE)['text']\n",
    "lin = pd.DataFrame([[i, 4] for i in lin], columns=['tweet', 'party'])\n",
    "\n",
    "data = data.append(lin, ignore_index=True)\n",
    "\n",
    "spd = pd.read_csv('../cleaned-data/SPD.csv',quoting=csv.QUOTE_NONE)['text']\n",
    "spd = pd.DataFrame([[i, 5] for i in spd], columns=['tweet', 'party'])\n",
    "\n",
    "data = data.append(spd, ignore_index=True)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7572a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading vocab and embedding matrix\n",
    "words = []\n",
    "em_matrix = np.genfromtxt(fname = \"../word_embedding/embeddings/vector_all_data_300d-3-5.tsv\", delimiter = \"\\t\" )       \n",
    "with open(\"../vocab/all_vocab_token.csv\", mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    next(reader) #skip header\n",
    "    vocab = {rows[0]:int(rows[2]) for rows in reader}\n",
    "# adding unknown token for new words\n",
    "vocab['UNK'] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dcc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming data\n",
    "# 1.) tokenizing\n",
    "# 2.) padding to length 50\n",
    "data['vectors'] = data['tweet'].apply([lambda x: [vocab[y.text] if y.text in vocab else vocab['UNK'] for y in nlp(str(x))]])\n",
    "data['vectors'] = data['vectors'].apply(lambda x: pad_sequences([x], maxlen=50, dtype=int, padding='post',value=0)[-1])\n",
    "data['len'] = data['vectors'].apply(lambda x: len(x))\n",
    "data_len = data['len'].max()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde5154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing label: transforming integer to vector\n",
    "y = tf.keras.utils.to_categorical(data['party'].to_numpy())\n",
    "y\n",
    "# preparing data (dataframe to np.array) \n",
    "X = np.array([np.array(x) for x in data['vectors']])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train/test/validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Test of model 1\n",
    "m = RnnModel(em_matrix, 300, 50)\n",
    "h = m.model.fit(X_train, y_train, epochs = 5, batch_size = 512, verbose = 1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd17ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for test 1\n",
    "plt.plot(h.history['accuracy'])\n",
    "plt.plot(h.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = m.model\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,7))\n",
    "# Block to evaluate training data\n",
    "yhat_test = model.predict(X_test)\n",
    "yhat_test = np.argmax(yhat_test, axis=1)\n",
    "\n",
    "y_label_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_test, yhat_test)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[0]).set_title('Test Data');\n",
    "\n",
    "\n",
    "# Block to evaluate test data\n",
    "yhat_train = model.predict(X_train)\n",
    "yhat_train = np.argmax(yhat_train, axis=1)\n",
    "\n",
    "y_label_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_train, yhat_train)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[1]).set_title('Train Data');\n",
    "plt.show()\n",
    "print('Party: \\t Test \\t Train\\nAfd:\\t',sum(y_label_test == 0), \"\\t\" , sum(y_label_train == 0))\n",
    "print('Union:\\t',sum(y_label_test == 1), \"\\t\" , sum(y_label_train == 1))\n",
    "print('FDP:\\t',sum(y_label_test == 2), \"\\t\" , sum(y_label_train == 2))\n",
    "print('Grüne:\\t',sum(y_label_test == 3), \"\\t\" , sum(y_label_train == 3))\n",
    "print('Linke:\\t',sum(y_label_test == 4), \"\\t\" , sum(y_label_train == 4))\n",
    "print('SPD:\\t',sum(y_label_test == 5), \"\\t\" , sum(y_label_train == 5))\n",
    "print('\\nAcc:\\t', \"{:2.2f}%\".format(accuracy_score(y_label_test,yhat_test)*100), \"{:2.2f}%\".format(accuracy_score(y_label_train,yhat_train)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e23339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing of saving and reloading weights\n",
    "model.save_weights(\"test_trail/my_weights_all_data_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing of saving and reloading weights\n",
    "loaded = RnnModel(em_matrix, 300, 50)\n",
    "loaded.model.load_weights(\"test_trail/my_weights_all_data_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b10946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#re-evaluation of loaded model\n",
    "l = loaded.model\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,7))\n",
    "# Block to evaluate training data\n",
    "yhat_test = l.predict(X_test)\n",
    "yhat_test = np.argmax(yhat_test, axis=1)\n",
    "\n",
    "y_label_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_test, yhat_test)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[0]).set_title('Test Data');\n",
    "\n",
    "\n",
    "# Block to evaluate test data\n",
    "yhat_train = l.predict(X_train)\n",
    "yhat_train = np.argmax(yhat_train, axis=1)\n",
    "\n",
    "y_label_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_train, yhat_train)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[1]).set_title('Train Data');\n",
    "plt.show()\n",
    "print('Party: \\t Test \\t Train\\nAfd:\\t',sum(y_label_test == 0), \"\\t\" , sum(y_label_train == 0))\n",
    "print('Union:\\t',sum(y_label_test == 1), \"\\t\" , sum(y_label_train == 1))\n",
    "print('FDP:\\t',sum(y_label_test == 2), \"\\t\" , sum(y_label_train == 2))\n",
    "print('Grüne:\\t',sum(y_label_test == 3), \"\\t\" , sum(y_label_train == 3))\n",
    "print('Linke:\\t',sum(y_label_test == 4), \"\\t\" , sum(y_label_train == 4))\n",
    "print('SPD:\\t',sum(y_label_test == 5), \"\\t\" , sum(y_label_train == 5))\n",
    "print('\\nAcc:\\t', \"{:2.2f}%\".format(accuracy_score(y_label_test,yhat_test)*100), \"{:2.2f}%\".format(accuracy_score(y_label_train,yhat_train)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d6e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Model (see first model)\n",
    "class RnnModel2():\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, max_len):\n",
    "        \n",
    "        inp1 = Input(shape=(max_len,))\n",
    "        x = Embedding(embedding_matrix.shape[0], embedding_dim, weights=[embedding_matrix])(inp1)\n",
    "        x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(128))(x)\n",
    "        x = Dense(256, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(64, activation=\"relu\")(x)\n",
    "        x = Dense(6, activation=\"softmax\")(x)    \n",
    "        model = Model(inputs=inp1, outputs=x)\n",
    "        model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4cae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing 2. model\n",
    "m2 = RnnModel2(em_matrix, 300, 50)\n",
    "h2 = m2.model.fit(X_train, y_train, epochs = 5, batch_size = 512, verbose = 1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing first model with more epochs\n",
    "m3 = RnnModel(em_matrix, 300, 50)\n",
    "h3 = m3.model.fit(X_train, y_train, epochs = 10, batch_size = 512, verbose = 1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of 2nd test\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,7))\n",
    "# Block to evaluate training data\n",
    "yhat_test = m2.model.predict(X_test)\n",
    "yhat_test = np.argmax(yhat_test, axis=1)\n",
    "\n",
    "y_label_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_test, yhat_test)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[0]).set_title('Test Data');\n",
    "\n",
    "\n",
    "# Block to evaluate test data\n",
    "yhat_train = m2.model.predict(X_train)\n",
    "yhat_train = np.argmax(yhat_train, axis=1)\n",
    "\n",
    "y_label_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_train, yhat_train)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[1]).set_title('Train Data');\n",
    "plt.show()\n",
    "print('Party: \\t Test \\t Train\\nAfd:\\t',sum(y_label_test == 0), \"\\t\" , sum(y_label_train == 0))\n",
    "print('Union:\\t',sum(y_label_test == 1), \"\\t\" , sum(y_label_train == 1))\n",
    "print('FDP:\\t',sum(y_label_test == 2), \"\\t\" , sum(y_label_train == 2))\n",
    "print('Grüne:\\t',sum(y_label_test == 3), \"\\t\" , sum(y_label_train == 3))\n",
    "print('Linke:\\t',sum(y_label_test == 4), \"\\t\" , sum(y_label_train == 4))\n",
    "print('SPD:\\t',sum(y_label_test == 5), \"\\t\" , sum(y_label_train == 5))\n",
    "print('\\nAcc:\\t', \"{:2.2f}%\".format(accuracy_score(y_label_test,yhat_test)*100), \"{:2.2f}%\".format(accuracy_score(y_label_train,yhat_train)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of 3nd test\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,7))\n",
    "# Block to evaluate training data\n",
    "yhat_test = m3.model.predict(X_test)\n",
    "yhat_test = np.argmax(yhat_test, axis=1)\n",
    "\n",
    "y_label_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_test, yhat_test)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[0]).set_title('Test Data');\n",
    "\n",
    "\n",
    "# Block to evaluate test data\n",
    "yhat_train = m3.model.predict(X_train)\n",
    "yhat_train = np.argmax(yhat_train, axis=1)\n",
    "\n",
    "y_label_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_train, yhat_train)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[1]).set_title('Train Data');\n",
    "plt.show()\n",
    "print('Party: \\t Test \\t Train\\nAfd:\\t',sum(y_label_test == 0), \"\\t\" , sum(y_label_train == 0))\n",
    "print('Union:\\t',sum(y_label_test == 1), \"\\t\" , sum(y_label_train == 1))\n",
    "print('FDP:\\t',sum(y_label_test == 2), \"\\t\" , sum(y_label_train == 2))\n",
    "print('Grüne:\\t',sum(y_label_test == 3), \"\\t\" , sum(y_label_train == 3))\n",
    "print('Linke:\\t',sum(y_label_test == 4), \"\\t\" , sum(y_label_train == 4))\n",
    "print('SPD:\\t',sum(y_label_test == 5), \"\\t\" , sum(y_label_train == 5))\n",
    "print('\\nAcc:\\t', \"{:2.2f}%\".format(accuracy_score(y_label_test,yhat_test)*100), \"{:2.2f}%\".format(accuracy_score(y_label_train,yhat_train)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34381348",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h2.history['accuracy'])\n",
    "plt.plot(h2.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39171043",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h3.history['accuracy'])\n",
    "plt.plot(h3.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a25ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Model\n",
    "class RnnModel3():\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, max_len):\n",
    "        \n",
    "        inp1 = Input(shape=(max_len,))\n",
    "        x = Embedding(embedding_matrix.shape[0], embedding_dim, weights=[embedding_matrix])(inp1)\n",
    "        x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(64))(x)\n",
    "        x = Dense(128, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(128, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(64, activation=\"relu\")(x)\n",
    "        x = Dense(6, activation=\"softmax\")(x)    \n",
    "        model = Model(inputs=inp1, outputs=x)\n",
    "        model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Test: 3. Model with 5 epochs\n",
    "m4 = RnnModel3(em_matrix, 300, 50)\n",
    "h4 = m4.model.fit(X_train, y_train, epochs = 5, batch_size = 512, verbose = 1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db8729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval of 4. Test\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,7))\n",
    "# Block to evaluate training data\n",
    "yhat_test = m4.model.predict(X_test)\n",
    "yhat_test = np.argmax(yhat_test, axis=1)\n",
    "\n",
    "y_label_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_test, yhat_test)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[0]).set_title('Test Data');\n",
    "\n",
    "\n",
    "# Block to evaluate test data\n",
    "yhat_train = m4.model.predict(X_train)\n",
    "yhat_train = np.argmax(yhat_train, axis=1)\n",
    "\n",
    "y_label_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_train, yhat_train)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[1]).set_title('Train Data');\n",
    "plt.show()\n",
    "print('Party: \\t Test \\t Train\\nAfd:\\t',sum(y_label_test == 0), \"\\t\" , sum(y_label_train == 0))\n",
    "print('Union:\\t',sum(y_label_test == 1), \"\\t\" , sum(y_label_train == 1))\n",
    "print('FDP:\\t',sum(y_label_test == 2), \"\\t\" , sum(y_label_train == 2))\n",
    "print('Grüne:\\t',sum(y_label_test == 3), \"\\t\" , sum(y_label_train == 3))\n",
    "print('Linke:\\t',sum(y_label_test == 4), \"\\t\" , sum(y_label_train == 4))\n",
    "print('SPD:\\t',sum(y_label_test == 5), \"\\t\" , sum(y_label_train == 5))\n",
    "print('\\nAcc:\\t', \"{:2.2f}%\".format(accuracy_score(y_label_test,yhat_test)*100), \"{:2.2f}%\".format(accuracy_score(y_label_train,yhat_train)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model\n",
    "class RnnModel4():\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, max_len):\n",
    "        \n",
    "        inp1 = Input(shape=(max_len,))\n",
    "        x = Embedding(embedding_matrix.shape[0], embedding_dim, weights=[embedding_matrix])(inp1)\n",
    "        x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(64))(x)\n",
    "        x = Dense(128, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(128, activation=\"relu\")(x)\n",
    "        x = Dense(64, activation=\"relu\")(x)\n",
    "        x = Dense(6, activation=\"softmax\")(x)    \n",
    "        model = Model(inputs=inp1, outputs=x)\n",
    "        model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Test: 4. Model with 5 epochs\n",
    "m5 = RnnModel4(em_matrix, 300, 50)\n",
    "h5 = m5.model.fit(X_train, y_train, epochs = 5, batch_size = 512, verbose = 1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e747bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval of 5. test\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,7))\n",
    "# Block to evaluate training data\n",
    "yhat_test = m5.model.predict(X_test)\n",
    "yhat_test = np.argmax(yhat_test, axis=1)\n",
    "\n",
    "y_label_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_test, yhat_test)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[0]).set_title('Test Data');\n",
    "\n",
    "\n",
    "# Block to evaluate test data\n",
    "yhat_train = m5.model.predict(X_train)\n",
    "yhat_train = np.argmax(yhat_train, axis=1)\n",
    "\n",
    "y_label_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_train, yhat_train)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[1]).set_title('Train Data');\n",
    "plt.show()\n",
    "print('Party: \\t Test \\t Train\\nAfd:\\t',sum(y_label_test == 0), \"\\t\" , sum(y_label_train == 0))\n",
    "print('Union:\\t',sum(y_label_test == 1), \"\\t\" , sum(y_label_train == 1))\n",
    "print('FDP:\\t',sum(y_label_test == 2), \"\\t\" , sum(y_label_train == 2))\n",
    "print('Grüne:\\t',sum(y_label_test == 3), \"\\t\" , sum(y_label_train == 3))\n",
    "print('Linke:\\t',sum(y_label_test == 4), \"\\t\" , sum(y_label_train == 4))\n",
    "print('SPD:\\t',sum(y_label_test == 5), \"\\t\" , sum(y_label_train == 5))\n",
    "print('\\nAcc:\\t', \"{:2.2f}%\".format(accuracy_score(y_label_test,yhat_test)*100), \"{:2.2f}%\".format(accuracy_score(y_label_train,yhat_train)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a33739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model plot\n",
    "for c,mode in enumerate([m,m2,m4,m5]):\n",
    "    plot_model(mode.model, to_file='models/Rnn' + str(c) + '.png', show_shapes = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914106c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving weights of all models\n",
    "models = [m, m2, m3, m4, m5]\n",
    "histories = [h, h2, h3, h4, h5]\n",
    "Model = [\"Rnn\", \"Rnn2\", \"Rnn\", \"Rnn3\", \"Rnn4\"]\n",
    "ep = [5, 5, 10, 5, 5]\n",
    "\n",
    "\n",
    "for ct, hx in enumerate(histories):\n",
    "    S = \"{mod}_ep{epo}_acc{acc}_valacc{valacc}\".format(\n",
    "        mod=Model[ct],\n",
    "        epo=ep[ct],\n",
    "        acc=\"{:2.2f}\".format(hx.history[\"accuracy\"][-1] * 100),\n",
    "        valacc=\"{:2.2f}\".format(hx.history[\"val_accuracy\"][-1]*100),\n",
    "    )\n",
    "    models[ct].model.save_weights('models/'+S+'/model_weights')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21be6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Model \n",
    "class RnnModel5():\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, max_len):\n",
    "        \n",
    "        inp1 = Input(shape=(max_len,))\n",
    "        x = Embedding(embedding_matrix.shape[0], embedding_dim, weights=[embedding_matrix])(inp1)\n",
    "        x = Bidirectional(LSTM(512, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(256))(x)\n",
    "        x = Dense(256, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(256, activation=\"relu\")(x)\n",
    "        x = Dense(64, activation=\"relu\")(x)\n",
    "        x = Dense(6, activation=\"softmax\")(x)    \n",
    "        model = Model(inputs=inp1, outputs=x)\n",
    "        model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ac3a3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test 6: Model 5 with 5 epochs\n",
    "m6 = RnnModel5(em_matrix, 300, 50)\n",
    "h6 = m6.model.fit(X_train, y_train, epochs = 5, batch_size = 512, verbose = 1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3497bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval of test 6\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,7))\n",
    "# Block to evaluate training data\n",
    "yhat_test = m6.model.predict(X_test)\n",
    "yhat_test = np.argmax(yhat_test, axis=1)\n",
    "\n",
    "y_label_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_test, yhat_test)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[0]).set_title('Test Data');\n",
    "\n",
    "\n",
    "# Block to evaluate test data\n",
    "yhat_train = m6.model.predict(X_train)\n",
    "yhat_train = np.argmax(yhat_train, axis=1)\n",
    "\n",
    "y_label_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_train, yhat_train)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[1]).set_title('Train Data');\n",
    "plt.show()\n",
    "print('Party: \\t Test \\t Train\\nAfd:\\t',sum(y_label_test == 0), \"\\t\" , sum(y_label_train == 0))\n",
    "print('Union:\\t',sum(y_label_test == 1), \"\\t\" , sum(y_label_train == 1))\n",
    "print('FDP:\\t',sum(y_label_test == 2), \"\\t\" , sum(y_label_train == 2))\n",
    "print('Grüne:\\t',sum(y_label_test == 3), \"\\t\" , sum(y_label_train == 3))\n",
    "print('Linke:\\t',sum(y_label_test == 4), \"\\t\" , sum(y_label_train == 4))\n",
    "print('SPD:\\t',sum(y_label_test == 5), \"\\t\" , sum(y_label_train == 5))\n",
    "print('\\nAcc:\\t', \"{:2.2f}%\".format(accuracy_score(y_label_test,yhat_test)*100), \"{:2.2f}%\".format(accuracy_score(y_label_train,yhat_train)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31989a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model-plot for test 6\n",
    "plot_model(m6.model, to_file='models/Rnn' + '5' + '.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving test 6\n",
    "S = \"{mod}_ep{epo}_acc{acc}_valacc{valacc}\".format(\n",
    "        mod='Rnn5',\n",
    "        epo=5,\n",
    "        acc=\"{:2.2f}\".format(h6.history[\"accuracy\"][-1] * 100),\n",
    "        valacc=\"{:2.2f}\".format(h6.history[\"val_accuracy\"][-1]*100),\n",
    "    )\n",
    "m6.model.save_weights('models/'+S+'/model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validating saved data\n",
    "m7 = RnnModel5(em_matrix, 300, 50)\n",
    "m7.model.load_weights(\"models/Rnn5_ep5_acc73.53_valacc56.80/model_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reevaluation test 6 after reload\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,7))\n",
    "# Block to evaluate training data\n",
    "yhat_test = m7.model.predict(X_test)\n",
    "yhat_test = np.argmax(yhat_test, axis=1)\n",
    "\n",
    "y_label_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_test, yhat_test)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[0]).set_title('Test Data');\n",
    "\n",
    "\n",
    "# Block to evaluate test data\n",
    "yhat_train = m7.model.predict(X_train)\n",
    "yhat_train = np.argmax(yhat_train, axis=1)\n",
    "\n",
    "y_label_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "mat = confusion_matrix(y_label_train, yhat_train)\n",
    "df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                  columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "\n",
    "sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[1]).set_title('Train Data');\n",
    "plt.show()\n",
    "print('Party: \\t Test \\t Train\\nAfd:\\t',sum(y_label_test == 0), \"\\t\" , sum(y_label_train == 0))\n",
    "print('Union:\\t',sum(y_label_test == 1), \"\\t\" , sum(y_label_train == 1))\n",
    "print('FDP:\\t',sum(y_label_test == 2), \"\\t\" , sum(y_label_train == 2))\n",
    "print('Grüne:\\t',sum(y_label_test == 3), \"\\t\" , sum(y_label_train == 3))\n",
    "print('Linke:\\t',sum(y_label_test == 4), \"\\t\" , sum(y_label_train == 4))\n",
    "print('SPD:\\t',sum(y_label_test == 5), \"\\t\" , sum(y_label_train == 5))\n",
    "print('\\nAcc:\\t', \"{:2.2f}%\".format(accuracy_score(y_label_test,yhat_test)*100), \"{:2.2f}%\".format(accuracy_score(y_label_train,yhat_train)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a46115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compact version for website\n",
    "# contains:\n",
    "# loading of matrix\n",
    "# creation of model class\n",
    "# loading of model weights\n",
    "em_matrix = np.genfromtxt(fname = \"../word_embedding/embeddings/vector_all_data_300d-3-5.tsv\", delimiter = \"\\t\" )\n",
    "class RnnModel2():\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, max_len):\n",
    "        \n",
    "        inp1 = Input(shape=(max_len,))\n",
    "        x = Embedding(embedding_matrix.shape[0], embedding_dim, weights=[embedding_matrix])(inp1)\n",
    "        x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(128))(x)\n",
    "        x = Dense(256, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(64, activation=\"relu\")(x)\n",
    "        x = Dense(6, activation=\"softmax\")(x)    \n",
    "        model = Model(inputs=inp1, outputs=x)\n",
    "        model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
    "        self.model = model\n",
    "        \n",
    "        \n",
    "loaded = RnnModel2(em_matrix, 300, 50)\n",
    "loaded.model.load_weights(\"models/Rnn5_ep5_acc73.53_valacc56.80/model_weights\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro2nlp",
   "language": "python",
   "name": "intro2nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
