{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import spacy\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, recall_score, precision_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for constructing confusion matrix\n",
    "# model is the name of the classifier to be used\n",
    "\n",
    "def plot_confusion_matrix(model, X_train, X_test, y_train, y_test):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16,7))\n",
    "    # Block to evaluate training data\n",
    "    yhat_test = model.predict(X_test)\n",
    "    #yhat_test = np.argmax(yhat_test, axis=1)\n",
    "    y_label_test = y_test\n",
    "\n",
    "    mat = confusion_matrix(y_label_test, yhat_test)\n",
    "    df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                      columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "    \n",
    "    sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[0]).set_title('Test Data');\n",
    "    \n",
    "    # Block to evaluate test data\n",
    "    yhat_train = model.predict(X_train)\n",
    "    y_label_train = y_train\n",
    "\n",
    "    mat = confusion_matrix(y_label_train, yhat_train)\n",
    "    df = pd.DataFrame(mat, index = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"],\n",
    "                      columns = [\"AfD\", \"Union\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\"])\n",
    "    \n",
    "    sn.heatmap(df, annot=True ,cmap='Blues', fmt='g', ax=axes[1]).set_title('Train Data');\n",
    "    plt.show()\n",
    "    print('Party: \\t Test \\t Train\\nAfd:\\t',sum(y_label_test == 0), \"\\t\" , sum(y_label_train == 0))\n",
    "    print('Union:\\t',sum(y_label_test == 1), \"\\t\" , sum(y_label_train == 1))\n",
    "    print('FDP:\\t',sum(y_label_test == 2), \"\\t\" , sum(y_label_train == 2))\n",
    "    print('Grüne:\\t',sum(y_label_test == 3), \"\\t\" , sum(y_label_train == 3))\n",
    "    print('Linke:\\t',sum(y_label_test == 4), \"\\t\" , sum(y_label_train == 4))\n",
    "    print('SPD:\\t',sum(y_label_test == 5), \"\\t\" , sum(y_label_train == 5))\n",
    "    # Accuracy for test and train data\n",
    "    print('\\nAcc:\\t', \"{:2.2f}%\".format(accuracy_score(y_label_test,yhat_test)*100), \"{:2.2f}%\".format(accuracy_score(y_label_train,yhat_train)*100))\n",
    "    print(\"\\n\"+classification_report(y_label_test, yhat_test,  digits=4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_pipeline () is the function to create the pipeline to be used\n",
    "def make_pipeline(vectorizer, model, verbose=True):\n",
    "    return Pipeline([(\"vectorizer\",vectorizer),\n",
    "                        (\"model\",model)], verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data frame for our tweets. Each party becomes a unique index from 0 to 5\n",
    "data = pd.DataFrame(columns=['tweet', 'party'])\n",
    "\n",
    "afd = pd.read_csv('../cleaned-data/AfD.csv')['text']\n",
    "afd = pd.DataFrame([[i, 0] for i in afd], columns=['tweet', 'party'])\n",
    "\n",
    "data = data.append(afd, ignore_index=True)\n",
    "\n",
    "cdu = pd.read_csv('../cleaned-data/CDU.csv')['text']\n",
    "csu = pd.read_csv('../cleaned-data/CSU.csv')['text']\n",
    "\n",
    "cdu = pd.DataFrame([[i, 1] for i in cdu], columns=['tweet', 'party'])\n",
    "csu = pd.DataFrame([[i, 1] for i in csu], columns=['tweet', 'party'])\n",
    "\n",
    "data = data.append(cdu, ignore_index=True)\n",
    "data = data.append(csu, ignore_index=True)\n",
    "\n",
    "fdp = pd.read_csv('../cleaned-data/FDP.csv')['text']\n",
    "fdp = pd.DataFrame([[i, 2] for i in fdp], columns=['tweet', 'party'])\n",
    "\n",
    "data = data.append(fdp, ignore_index=True)\n",
    "\n",
    "gru = pd.read_csv('../cleaned-data/GRÜNE.csv')['text']\n",
    "gru = pd.DataFrame([[i, 3] for i in gru], columns=['tweet', 'party'])\n",
    "\n",
    "data = data.append(gru, ignore_index=True)\n",
    "\n",
    "lin = pd.read_csv('../cleaned-data/LINKE.csv')['text']\n",
    "lin = pd.DataFrame([[i, 4] for i in lin], columns=['tweet', 'party'])\n",
    "\n",
    "data = data.append(lin, ignore_index=True)\n",
    "\n",
    "spd = pd.read_csv('../cleaned-data/SPD.csv')['text']\n",
    "spd = pd.DataFrame([[i, 5] for i in spd], columns=['tweet', 'party'])\n",
    "\n",
    "data = data.append(spd, ignore_index=True)\n",
    "\n",
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading a large spacy model for German\n",
    "#!python -m spacy download de_core_news_lg\n",
    "nlp = spacy.load('de_core_news_lg')\n",
    "\n",
    "# Function to lemmatize our words\n",
    "def spacy_tokenizer(tweet):\n",
    "    # Creating our token object\n",
    "    mytokens = nlp(tweet)\n",
    "\n",
    "  # Lemmatizing each token\n",
    "    mytokens = [word.lemma_.strip() for word in mytokens if word.lemma_ != \"-PRON-\" ]\n",
    "\n",
    "  # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our data \n",
    "X_train, X_test, y_train, y_test = train_test_split(data['tweet'], data['party'].to_numpy(dtype=np.int64),\n",
    "                                                        random_state=42, test_size=0.30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using lemmatization. Make pipeline with CountVectorizer and LinearSVC classifier\n",
    "pipe_svc_cnt_lem = make_pipeline(CountVectorizer(tokenizer=spacy_tokenizer), LinearSVC(max_iter=10000, dual=False), True)\n",
    "pipe_svc_cnt_lem.fit(X_train, y_train)\n",
    "dump(pipe_svc_cnt_lem, 'pipe_svc_cnt_lem.joblib') # Saving our fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and analyzing the trained model\n",
    "svc_model_cnt_lem = load('pipe_svc_cnt_lem.joblib') \n",
    "print(\"Report for the LinearSVC model with CountVectorizer and lemmatization\")\n",
    "plot_confusion_matrix(svc_model_cnt_lem, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using lemmatization. Make pipeline with TfidfVectorizer and LinearSVC classifier\n",
    "pipe_tfidf_cnt_lem = make_pipeline(TfidfVectorizer(tokenizer=spacy_tokenizer), LinearSVC(max_iter=10000, dual=False), True)\n",
    "pipe_tfidf_cnt_lem.fit(X_train, y_train)\n",
    "dump(pipe_tfidf_cnt_lem, 'pipe_tfidf_cnt_lem.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and analyzing the trained model\n",
    "pipe_svc_tfidf_lem = load('pipe_tfidf_cnt_lem.joblib')\n",
    "print(\"Report for the LinearSVC model with TFidfVectorizer and lemmatization\")\n",
    "plot_confusion_matrix(pipe_svc_tfidf_lem, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipelines for the CountVectorizer and various classifiers\n",
    "pipe_svc_cnt = make_pipeline(CountVectorizer(), LinearSVC(max_iter=10000, dual=False), True)\n",
    "pipe_lg_cnt = make_pipeline(CountVectorizer(), \n",
    "                            LogisticRegression(max_iter=10000, solver='lbfgs', dual=False, random_state=0), True)\n",
    "pipe_nb_cnt = make_pipeline(CountVectorizer(), MultinomialNB(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc_cnt.fit(X_train, y_train)\n",
    "dump(pipe_svc_cnt, 'pipe_svc_cnt.joblib')\n",
    "\n",
    "pipe_lg_cnt.fit(X_train, y_train)\n",
    "dump(pipe_lg_cnt, 'pipe_lg_cnt.joblib')\n",
    "\n",
    "pipe_nb_cnt.fit(X_train, y_train)\n",
    "dump(pipe_nb_cnt, 'pipe_nb_cnt.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipelines for the TfidfVectorizer and various classifiers\n",
    "pipe_svc_tfidf = make_pipeline(TfidfVectorizer(), LinearSVC(max_iter=10000, dual=False), True)\n",
    "pipe_lg_tfidf = make_pipeline(TfidfVectorizer(), \n",
    "                            LogisticRegression(max_iter=10000, solver='lbfgs', dual=False, random_state=0), True)\n",
    "pipe_nb_tfidf = make_pipeline(TfidfVectorizer(), MultinomialNB(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc_tfidf.fit(X_train,y_train)\n",
    "dump(pipe_svc_tfidf, 'pipe_svc_tfidf.joblib')\n",
    "\n",
    "pipe_lg_tfidf.fit(X_train,y_train)\n",
    "dump(pipe_lg_tfidf, 'pipe_lg_tfidf.joblib')\n",
    "\n",
    "pipe_nb_tfidf.fit(X_train,y_train)\n",
    "dump(pipe_nb_tfidf, 'pipe_nb_tfidf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of results for CountVectorizer and TfIdfVectorizer for LinearSVC classifier\n",
    "svc_model_cnt = load('pipe_svc_cnt.joblib')\n",
    "print(\"Report for the LinearSVC model with CountVectorizer\")\n",
    "plot_confusion_matrix(svc_model_cnt, X_train, X_test, y_train, y_test)\n",
    "svc_model_tfidf = load('pipe_svc_tfidf.joblib')\n",
    "print(\"Report for the LinearSVC model with TfIdfVectorizer\")\n",
    "plot_confusion_matrix(svc_model_tfidf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of results for CountVectorizer and TfIdfVectorizer for LogisticRegression classifier\n",
    "lg_model_cnt = load('pipe_lg_cnt.joblib')\n",
    "print(\"Report for the LogisticRegression model with CountVectorizer\")\n",
    "plot_confusion_matrix(lg_model_cnt, X_train, X_test, y_train, y_test)\n",
    "lg_model_tfidf = load('pipe_lg_tfidf.joblib')\n",
    "print(\"Report for the LogisticRegression model with TfIdfVectorizer\")\n",
    "plot_confusion_matrix(lg_model_tfidf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of results for CountVectorizer and TfIdfVectorizer for MultinomialNB classifier\n",
    "nb_model_cnt = load('pipe_nb_cnt.joblib')\n",
    "print(\"Report for the MultinomialNB model with CountVectorizer\")\n",
    "plot_confusion_matrix(nb_model_cnt, X_train, X_test, y_train, y_test)\n",
    "nb_model_tfidf = load('pipe_nb_tfidf.joblib')\n",
    "print(\"Report for the MultinomialNB model with TfIdfVectorizer\")\n",
    "plot_confusion_matrix(nb_model_tfidf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
